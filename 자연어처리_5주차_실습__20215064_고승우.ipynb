{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whatnews72/----/blob/master/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_5%EC%A3%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5__20215064_%EA%B3%A0%EC%8A%B9%EC%9A%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"5주차_실습1_seq2seq_encoder_decoder번역_수강생용.ipynb\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import requests\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Downloading and extracting the dataset\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "def download(url, file_name):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\"\n",
        "    }\n",
        "    with open(file_name, \"wb\") as f:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        f.write(response.content)\n",
        "\n",
        "download(url, zipfilename)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "# Reading the data\n",
        "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
        "lines = lines[['src', 'tar']]\n",
        "lines = lines[:60000]  # Limiting to 60,000 samples\n",
        "\n",
        "# Adding special tokens\n",
        "lines['tar'] = lines['tar'].apply(lambda x: '\\t ' + x + ' \\n')\n",
        "\n",
        "# Building the vocabularies\n",
        "src_tokenizer = get_tokenizer('basic_english')\n",
        "tar_tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "src_vocab = build_vocab_from_iterator(yield_tokens(lines['src'], src_tokenizer), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "tar_vocab = build_vocab_from_iterator(yield_tokens(lines['tar'], tar_tokenizer), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "\n",
        "src_vocab.set_default_index(src_vocab[\"<unk>\"])\n",
        "tar_vocab.set_default_index(tar_vocab[\"<unk>\"])\n",
        "\n",
        "# Display vocabulary sizes\n",
        "print(f\"Source vocabulary size: {len(src_vocab)}\")\n",
        "print(f\"Target vocabulary size: {len(tar_vocab)}\")\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, data, src_vocab, tar_vocab, src_tokenizer, tar_tokenizer):\n",
        "        self.data = data\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tar_vocab = tar_vocab\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.tar_tokenizer = tar_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.data.iloc[idx]['src']\n",
        "        tar = self.data.iloc[idx]['tar']\n",
        "\n",
        "        src_indices = [self.src_vocab[token] for token in self.src_tokenizer(src)]\n",
        "        tar_indices = [self.tar_vocab[token] for token in self.tar_tokenizer(tar)]\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tar_indices)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tar_batch = zip(*batch)\n",
        "    src_batch = nn.utils.rnn.pad_sequence(src_batch, padding_value=src_vocab[\"<pad>\"])\n",
        "    tar_batch = nn.utils.rnn.pad_sequence(tar_batch, padding_value=tar_vocab[\"<pad>\"])\n",
        "    return src_batch, tar_batch\n",
        "\n",
        "dataset = TranslationDataset(lines, src_vocab, tar_vocab, src_tokenizer, tar_tokenizer)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "valid_size = len(dataset) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "valid_iterator = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[0, :]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(model.device), trg.to(model.device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(model.device), trg.to(model.device)\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "# Hyperparameters\n",
        "INPUT_DIM = len(src_vocab)\n",
        "OUTPUT_DIM = len(tar_vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# Initialize encoder and decoder\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize seq2seq model\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab['<pad>'])\n",
        "\n",
        "# Example training loop\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "\n",
        "# Example inference\n",
        "def translate_sentence(sentence, src_vocab, tar_vocab, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [token.lower() for token in sentence.split()]\n",
        "    tokens = [src_vocab[\"<bos>\"]] + [src_vocab[token] for token in tokens] + [src_vocab[\"<eos>\"]]\n",
        "\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [tar_vocab[\"<bos>\"]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == tar_vocab[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [tar_vocab.lookup_token(i) for i in trg_indexes]\n",
        "\n",
        "    return trg_tokens[1:]\n",
        "\n",
        "# Example usage\n",
        "sentence = \"A man is walking.\"\n",
        "\n",
        "translation = translate_sentence(sentence, src_vocab, tar_vocab, model, device)\n",
        "print(f'predicted trg: {\" \".join(translation)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiGcxbPqEuuw",
        "outputId": "387372bb-eadb-4e7d-d740-194be4b1d07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source vocabulary size: 6531\n",
            "Target vocabulary size: 12826\n",
            "Epoch: 01\n",
            "\tTrain Loss: 4.511\n",
            "\t Val. Loss: 4.091\n",
            "Epoch: 02\n",
            "\tTrain Loss: 3.384\n",
            "\t Val. Loss: 3.611\n",
            "Epoch: 03\n",
            "\tTrain Loss: 2.818\n",
            "\t Val. Loss: 3.329\n",
            "Epoch: 04\n",
            "\tTrain Loss: 2.463\n",
            "\t Val. Loss: 3.181\n",
            "Epoch: 05\n",
            "\tTrain Loss: 2.185\n",
            "\t Val. Loss: 3.071\n",
            "Epoch: 06\n",
            "\tTrain Loss: 1.972\n",
            "\t Val. Loss: 2.992\n",
            "Epoch: 07\n",
            "\tTrain Loss: 1.814\n",
            "\t Val. Loss: 2.938\n",
            "Epoch: 08\n",
            "\tTrain Loss: 1.677\n",
            "\t Val. Loss: 2.911\n",
            "Epoch: 09\n",
            "\tTrain Loss: 1.565\n",
            "\t Val. Loss: 2.894\n",
            "Epoch: 10\n",
            "\tTrain Loss: 1.466\n",
            "\t Val. Loss: 2.854\n",
            "predicted trg: un homme homme est . . . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? . . . . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}